Current:
Central Control: Supervisor acts as the central server, handling all allocation decisions.
Graph Model: Uses NetworkX to model the environment grid, allowing for Dijkstra's shortest path routing.
Communication: Utilizes Webots Emitter and Receiver for JSON message passing (requests, status, assignment).
Task Management: Tasks are stored in a Priority Queue (heapq) to ensure higher-priority jobs are considered first.
Enforce a 10% battery reserve buffer, rerouting robots to charging if post-task battery falls below threshold.
Use a multi-factor cost model incorporating distance, load, battery, congestion, and expected delays.


Future Enhancements
Continuously learn each robot’s true speed from telemetry and use it in future ETA and cost predictions.
Provide accurate ETA estimates that combine motion time, pickup time, load-dependent slowdown, and queue delays.
Support dynamic path replanning based on congestion, blockages, and higher-priority reroutes.
Add the concept of time to cost as well

Hero Features
Implement self-learning cost refinement, where robots update bidding parameters from historical performance data.
Introduce proximity-aware reassignment, where tasks can be reassigned mid-route if another robot becomes closer or faster.
Compute cost for all robots including busy ones, enabling future-task scheduling rather than idle-only bidding.
Explore combinatorial auctions so robots can bid on bundles of tasks when routing synergies reduce total cost.




Future Reference:
This sophisticated market-based allocation algorithm utilizes a Normalized Time-Energy-Risk Utility Function to calculate a bid price denominated entirely in seconds, ensuring all cost factors are physically comparable and grounded in reality. The algorithm aggregates three primary components: Execution Cost, which measures the travel time required for the pickup and delivery legs, applying a weighted penalty to non-productive "deadheading" (travel to pickup); Recovery Cost, which translates the estimated energy consumption—calculated using the robot's specific, learned motor efficiency—into the future time required to recharge that exact amount of energy; and a Scarcity Risk Barrier, which employs an exponential function to impose a negligible penalty when battery reserves are high but causes the cost to skyrocket mathematically as the energy buffer approaches the critical 10% safety threshold. This aggregated physical cost is finally scaled by the task’s priority, acting as a "willingness to pay" factor that allows high-priority missions to effectively discount the safety margins, ensuring that the fleet automatically balances logistical speed, individual hardware health, and mission urgency without relying on arbitrary magic numbers.
